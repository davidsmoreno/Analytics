---
title: "Tarea 1 Mineria de Datos"
author: "David Moreno, Luisa y David"
date: "`r format(Sys.time(), '%Y-%m-%d')`"
output:
  html_document:
    toc: true
    toc_float: true
    number_sections: true
    theme: cosmo
    highlight: tango
---

# Punto 1

Para el desarrollo del primer punto vamos a ver los resultados obtenidos utilizando algunas tecnicas de eliminación de Outliers, y comparando los resultados 


## Punto 1.1
Primero lo que debemos unir las bases de datos, idenrificando si hay fechas repetidas en cuyo caso se debe quedar con el primer registro. Por último, se debe usar una técnica de imputación(asignación o eliminación) para los datos faltantes.


```{r, warning=FALSE}
# Read Inflow Data
weather <- read_excel("WeatherData_1.xlsx", skip = 1, col_names = c("Date", "Rainfall depth (mm)", "Air temperature (°C)", "Air humidity (%)", "Windspeed (km/h)"))

# Read inflow data
inflow <- read_excel("InflowData_1.xlsx", skip = 1, col_names = c("Date", "DMA A", "DMA B", "DMA C", "DMA D", "DMA E", "DMA F", "DMA G", "DMA H", "DMA I", "DMA J"))

# Convert Date column to POSIXct format
weather$Date <- as.POSIXct(weather$Date, format = "%d/%m/%Y %H:%M")
inflow$Date <- as.POSIXct(inflow$Date, format = "%d/%m/%Y %H:%M")

# Merge inflow and weather data frames by "Date" column, retaining all rows from inflow
df_data <- merge(inflow, weather, by = "Date", all.x = TRUE)

# Remove duplicate rows based on the Date column, keeping only the first occurrence
df_data <- df_data[!duplicated(df_data$Date, fromLast = TRUE), ]

```

Primero, leemos los dos conjuntos de datos y renombramos las columnas con nombres descriptivos. Utilizamos "Date" como nombre común para facilitar la unión de los conjuntos.

A continuación, convertimos la columna "Date" en el formato POSIXct para asegurarnos de que esté en el formato correcto, que es día/mes/año/hora/minuto.

Posteriormente, creamos la variable df_data y unimos las dos bases de datos, las unimos haciendo un left join de la base de datos Inflow con la base weather.

### Procesamiento de los datos

```{r}
str(df_data)
```
Aqui vemos que los tipos de datos de las las columnas son númericos y de tipo chr que es string, acá vemos un problema y es que esta tomando el string "#N/A" no como vacio sino como string, las demás variables de DMA deberian ser númericas para esto vamos a hacer una tranformación a los datos 



```{r}
df_data <- df_data %>%
  mutate(
    # First operation: Handle character columns
    across(where(is.character), ~ {
      # Replace "#N/A" with NA, then extract numbers and convert to numeric
      as.numeric(gsub("[^0-9.]+", "", ifelse(. == "#N/A", NA, .)))
    }),
    # Second operation: Convert DMA columns to integer
    across(c(`DMA A`, `DMA B`, `DMA C`, `DMA D`, `DMA E`, `DMA F`, `DMA G`, `DMA H`, `DMA I`, `DMA J`), as.integer)
  )
str(df_data)
```

Aqui hacemos un pipeline indicando que remplace todos los strings de la forma "#NA" con NA de variable descriptiva en r, luego extraiga los numeros y los combierta a numerico, y luego convertimos toda las columnas en enteros. Para poder iniciar con el desarrollo de manejo de llenar los NA

### Tecnica de imputacion

Para este ejericio vamos a ver la cantidad de Na que tenemos en cada columns para ver que método utilizamos

```{r}
# Calculate NA proportions for each column
na_proportions <- colMeans(is.na(df_data))

# Create a data frame with column names and NA proportions
na_summary <- data.frame(
  Column = names(na_proportions),
  NA_Proportion = na_proportions
)

# Arrange the summary data frame by NA proportions in descending order
na_summary <- na_summary %>%
  arrange(desc(NA_Proportion))

# Print the summary
print(na_summary)

```

Aqui vemos el porcentaje más grande de valores vacios es 0.13 seguido de 0.11 y 0.10 porciento de DMA G, donde el porcentage de valores vacios es mayor, Para el desarollo de esta actividad vamos a eliminar estos valores. Pero podría ser interesanete también hacer un análisis con los valores de la media.

```{r }

#Primer analisis eliminar NA
df_data_1<-na.omit(df_data)

```

### Histogramas de las columnas


```{r, fig.width=12, fig.height=10}
# Identify numeric columns. This is a placeholder; replace it with your actual logic to identify numeric columns
numeric_cols <- sapply(df_data_1, is.numeric)

# Set up the plotting window to display multiple plots based on the number of numeric columns
par(mfrow=c(ceiling(sqrt(sum(numeric_cols))), ceiling(sqrt(sum(numeric_cols)))))

# Loop through each numeric column to create a histogram
for(col in names(df_data_1)[numeric_cols]) {
  hist(df_data_1[[col]], main = paste("Histogram of", col),
       xlab = col, ylab = "Frequency")
}

# Reset plotting window to default
par(mfrow=c(1, 1))

```
Aquí realizamos un gráfico para visualizar las distribuciones de nuestras columnas y comprender mejor la naturaleza de los datos de cada variable. Observamos que la variable "Rainfall depth" presenta una alta concentración de valores en cero, lo que indica que la información disponible para esta variable es limitada, ya que la mayoría de los registros tienen un valor de cero.

Además, al analizar los datos en general, identificamos posibles valores atípicos ("outliers") (Para el Bono) en la columna DMA A, particularmente para valores mayores a 15. 



## Punto 1.2
Se desea identificar si se tiene un patrón dentro de las series de tiempo, para esto se debe usar la técnica de media móvil variando la ventada de tiempo que se usa para cada corrida. Se le indica que debe usar 5 ventanas de tiempo diferentes para compara los resultados y asi poder conluir sobre el patrón en cada serie de tiempo.







## 1.3 
Asimimso, se el pide que busque variables que tengan una relación con el consumo de cada una de las áreas mostradas en la tabla 1.


## Bono
El dataset inclute posible outliers. Identifique, elimine y compare los resultados obtenidos.






